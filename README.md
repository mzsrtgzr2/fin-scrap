
sources
- https://github.com/arathus/onlab2021/blob/0c35993bbf33139c5ccb9777d287e491bf110b53/jakubakos_VR7Z03/data_gathering/collector(good).py

- https://github.com/phbrgnomo/CryptoTradingTools/tree/main
- https://medium.com/@saabeilin/kafka-hands-on-part-ii-producing-and-consuming-messages-in-python-44d5416f582e


- https://sparkbyexamples.com/spark/spark-streaming-consume-and-produce-kafka-messages-in-avro-format/

parquet:
- https://arrow.apache.org/docs/python/ipc.html#writing-and-reading-streams
- https://mypersonalmusingsblog.wpcomstaging.com/2018/08/21/handling-large-amounts-of-data-with-parquet-part-1/
- https://arrow.apache.org/docs/python/parquet.html#writing-metadata-and-common-medata-files

arrow / vaex
- https://towardsdatascience.com/apache-arrow-read-dataframe-with-zero-memory-69634092b1a 
- https://towardsdatascience.com/process-dataset-with-200-million-rows-using-vaex-ad4839710d3b